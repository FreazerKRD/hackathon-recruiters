{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "811098ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "328f7ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.desired_capabilities import DesiredCapabilities\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "import time\n",
    "import csv\n",
    "import re\n",
    "import pickle\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fec1241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверка существования элемента на странице\n",
    "def check_exists_element(by, path):\n",
    "    try:\n",
    "        driver.find_element(by, path)\n",
    "    except NoSuchElementException:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b88b098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция авторизации\n",
    "def auth(driver):\n",
    "    # Авторизация по cookies\n",
    "    if os.path.exists(FILES_PATH + COOKIES_PATH):\n",
    "        driver.get('https://linkedin.com')\n",
    "        #Загрузка куки\n",
    "        for cookie in pickle.load(open(FILES_PATH + COOKIES_PATH, 'rb')):\n",
    "            driver.add_cookie(cookie)\n",
    "        time.sleep(random.uniform(.5, 1))\n",
    "        driver.refresh()\n",
    "        time.sleep(random.uniform(.5, 2))\n",
    "\n",
    "    # Вход по паролю и сохранение cookies\n",
    "    else:\n",
    "        driver.get('https://linkedin.com/uas/login')\n",
    "        #Авторизация\n",
    "        time.sleep(random.uniform(2, 4))\n",
    "        username = driver.find_element(By.ID, \"username\")\n",
    "        username.send_keys(str(input('Введите логин: ')))\n",
    "        pword = driver.find_element(By.ID, \"password\")\n",
    "        pword.send_keys(str(input('Введите пароль: ')))\n",
    "        driver.find_element(By.XPATH, \"//button[@type='submit']\").click()\n",
    "        time.sleep(30) #время на ввод кода подтверждения если понадобится\n",
    "        pickle.dump(driver.get_cookies(), open(FILES_PATH + COOKIES_PATH, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8cbbd52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция парсит страницы поиска\n",
    "def search_pages(driver):\n",
    "    for i in range(NUM_PAGES_TO_PARSE):\n",
    "        # Задержка для полной загрузки страницы\n",
    "        time.sleep(random.uniform(4, 7))\n",
    "\n",
    "        last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        NUM_SCROLLS = 20\n",
    "\n",
    "        for _ in range(NUM_SCROLLS):\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(random.uniform(1.5, 3))\n",
    "            new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            if new_height == last_height:\n",
    "                break\n",
    "            last_height = new_height\n",
    "\n",
    "        search_result_links = driver.find_elements(By.CSS_SELECTOR, \"span.entity-result__title-text a.app-aware-link\")\n",
    "\n",
    "        profile_urls = []\n",
    "        \n",
    "        for link in search_result_links:\n",
    "            href = link.get_attribute(\"href\")\n",
    "            if 'linkedin.com/in' in href:\n",
    "                profile_urls.append(href)\n",
    "                \n",
    "        profile_urls = pd.Series(profile_urls)\n",
    "        profile_urls_cut = profile_urls.str.split('?', n=1).str[0]\n",
    "        \n",
    "        time.sleep(random.uniform(2, 5))\n",
    "        \n",
    "        # Парсинг информации о пользователях и их постах\n",
    "        # Создаем файл для записи инфо о пользователях если он не существует\n",
    "        if not os.path.exists(INFO_FILE_NAME):\n",
    "            header = ['name', 'status', 'company', 'profile_url']\n",
    "            with open(INFO_FILE_NAME, 'w', newline='', encoding='utf-8') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow(header)\n",
    "                \n",
    "        #Создаем файл для записи постов если он не существует\n",
    "        if not os.path.exists(POSTS_FILE_NAME):\n",
    "            header = ['url', 'text', 'likes_cnt', 'reposts_cnt', 'comments_cnt']\n",
    "            with open(POSTS_FILE_NAME, 'w', newline='', encoding='utf-8') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow(header)\n",
    "\n",
    "        # Получение информации из профилей пользователей\n",
    "        for url in profile_urls_cut:\n",
    "            get_and_save_profile_info(driver, url)\n",
    "            time.sleep(random.uniform(55, 75))\n",
    "\n",
    "        print('Current search page completly parsed:')\n",
    "        print(driver.current_url)\n",
    "        print('- ' * 25)\n",
    "\n",
    "        next_button = driver.find_element(By.CSS_SELECTOR, 'button.artdeco-pagination__button--next')\n",
    "        next_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4c1be79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_save_profile_info(driver, profile_url):\n",
    "    info_source = []\n",
    "    \n",
    "    # This will open the link\n",
    "    driver.get(profile_url)\n",
    "    \n",
    "    # Random sleeping time to load all data\n",
    "    time.sleep(random.uniform(5, 7))\n",
    "\n",
    "    # Extracting data from page with BeautifulSoup\n",
    "    src = driver.page_source\n",
    "\n",
    "    # Now using beautiful soup    \n",
    "    soup = BeautifulSoup(src, 'lxml')\n",
    "\n",
    "    # Extracting the HTML of the complete introduction box\n",
    "    # that contains the name, status, and the location\n",
    "    intro = soup.find('div', {'class': 'pv-text-details__left-panel'})\n",
    "    \n",
    "    # Extracting the Name\n",
    "    # In case of an error, try changing the tags used here.\n",
    "    name_loc = intro.find(\"h1\")\n",
    "    # strip() is used to remove any extra blank spaces\n",
    "    name = name_loc.get_text().strip()\n",
    "    info_source.append(name)\n",
    "\n",
    "    # This gives us the HTML of the tag in which user status is present\n",
    "    status_loc = intro.find(\"div\", {'class': 'text-body-medium'})\n",
    "    # Extracting user status\n",
    "    status = status_loc.get_text().strip()\n",
    "    info_source.append(status)\n",
    "    \n",
    "    # Extracting the Company name\n",
    "    work_space = soup.find('ul', {'class': 'pv-text-details__right-panel'})\n",
    "    # This gives us the HTML of the tag in which the Company Name is present\n",
    "    works_at_loc = work_space.find('span', {'class': 'pv-text-details__right-panel-item-text'})\n",
    "    # Extracting the Company Name\n",
    "    works_at = works_at_loc.get_text().strip()\n",
    "    info_source.append(works_at)\n",
    "\n",
    "    # Добавил случайный скроллинг страницы для имитации человека\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    NUM_SCROLLS = random.randint(4, 10)\n",
    "\n",
    "    for _ in range(NUM_SCROLLS):\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(random.uniform(1.5, 3))\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "    time.sleep(random.uniform(2, 5))\n",
    "    \n",
    "    # Add user profile URL\n",
    "    info_source.append(profile_url)\n",
    "    \n",
    "    # Сохранение в файл\n",
    "    with open(INFO_FILE_NAME, 'a', newline='', encoding='utf-8') as file:\n",
    "        writer_obj = csv.writer(file)\n",
    "        writer_obj.writerow(info_source)\n",
    "        \n",
    "    # Собираем посты текущего пользователя, если они существуют\n",
    "    by = By.CSS_SELECTOR\n",
    "    path = 'li.profile-creator-shared-feed-update__mini-container'\n",
    "    if check_exists_element(by, path):\n",
    "        get_and_save_users_posts(driver, profile_url)\n",
    "        \n",
    "    time.sleep(random.uniform(1, 3))\n",
    "    \n",
    "    # Возврат на страницу поиска\n",
    "    driver.execute_script(\"window.history.go(-1)\")\n",
    "\n",
    "    # Print collected data\n",
    "#     print(\"Name -->\",  name,\n",
    "#           \"\\nStatus -->\", status,\n",
    "#           \"\\nWorks At -->\", works_at,\n",
    "#           \"\\nProfile URL -->\", cur_profile_url)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47867bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_save_users_posts(driver, url):\n",
    "    driver.get(url + '/recent-activity/all/')\n",
    "    time.sleep(random.uniform(4, 7))\n",
    "    SCROLL_PAUSE_TIME = random.uniform(1, 3)\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    \n",
    "    # We can adjust this number to get more posts\n",
    "    NUM_SCROLLS = random.randint(7, 10)\n",
    "    for i in range(NUM_SCROLLS):\n",
    "    \n",
    "        # Scroll down to bottom\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "        # Wait to load page\n",
    "        time.sleep(random.uniform(3,6))\n",
    "\n",
    "        # Calculate new scroll height and compare with last scroll height\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "\n",
    "        last_height = new_height\n",
    "\n",
    "    src = driver.page_source\n",
    "    \n",
    "    # Установил lxml\n",
    "    soup = BeautifulSoup(src, 'lxml')\n",
    "    posts = soup.find_all('li', class_='profile-creator-shared-feed-update__container')\n",
    "\n",
    "    for post_src in posts:\n",
    "        post_source = []\n",
    "        post_source.append(url)\n",
    "\n",
    "        # Текст статьи репоста\n",
    "        post_text_div = post_src.find('a', {'class': 'tap-target update-components-mini-update-v2__link-to-details-page text-body-medium ember-view'})\n",
    "        if post_text_div is not None:\n",
    "            post_text = post_text_div.find('span', {'dir': 'ltr'})\n",
    "        else:\n",
    "            post_text = None\n",
    "\n",
    "        if post_text is not None:\n",
    "            post_text = post_text.get_text().strip()\n",
    "\n",
    "        if post_text is None:\n",
    "            post_text_div = post_src.find('div', {'class': 'feed-shared-update-v2__description-wrapper mr2'})            \n",
    "            if post_text_div is not None:\n",
    "                post_text = post_text_div.find('span', {'dir': 'ltr'})\n",
    "            else:\n",
    "                post_text = None\n",
    "\n",
    "            # If post text is found\n",
    "            if post_text is not None:\n",
    "                post_text = post_text.get_text().strip()\n",
    "            else:\n",
    "                post_text = 'No text'\n",
    "\n",
    "        post_source.append(post_text)\n",
    "\n",
    "        # Подсчет лайков\n",
    "        likes_cnt = post_src.find('span', {'class': 'social-details-social-counts__reactions-count'})\n",
    "\n",
    "        # If number of reactions is written as text\n",
    "        # It has different class name\n",
    "        if likes_cnt is None:\n",
    "            likes_cnt = post_src.find('span', {'class': 'social-details-social-counts__social-proof-text'})\n",
    "\n",
    "\n",
    "        if likes_cnt is not None:\n",
    "            likes_cnt = likes_cnt.get_text().strip()\n",
    "        else:\n",
    "            likes_cnt = 0\n",
    "\n",
    "        post_source.append(likes_cnt)\n",
    "\n",
    "        # Подсчет репостов\n",
    "        reposts_cnt = post_src.find('li', {'class': 'social-details-social-counts__item social-details-social-counts__item--with-social-proof'})\n",
    "        if reposts_cnt is not None:\n",
    "            reposts_cnt = reposts_cnt.find('span', {'aria-hidden': 'true'})\n",
    "        if reposts_cnt is not None:\n",
    "            reposts_cnt = reposts_cnt.get_text().strip()\n",
    "        else:\n",
    "            reposts_cnt = 0 \n",
    "        post_source.append(reposts_cnt)\n",
    "\n",
    "        # Подсчет комментариев\n",
    "        comment_cnt = post_src.find('li', {'class': 'social-details-social-counts__item social-details-social-counts__comments social-details-social-counts__item--with-social-proof'})\n",
    "        if comment_cnt is not None:\n",
    "            comment_cnt = comment_cnt.find('span', {'aria-hidden': 'true'})\n",
    "        if comment_cnt is not None:\n",
    "            comment_cnt = comment_cnt.get_text().strip()\n",
    "        else:\n",
    "            comment_cnt = 0 \n",
    "\n",
    "        post_source.append(comment_cnt)          \n",
    "        \n",
    "        # Сохранение в файл\n",
    "        with open(POSTS_FILE_NAME, 'a', newline='', encoding='utf-8') as file:\n",
    "            writer_obj = csv.writer(file)\n",
    "            writer_obj.writerow(post_source)\n",
    "            \n",
    "        time.sleep(random.uniform(2, 5))\n",
    "    \n",
    "    # Возврат на страницу профиля\n",
    "    driver.execute_script(\"window.history.go(-1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1c3c0e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Введите количество страниц для парсинга: 1\n",
      "Введите строку поиска: https://www.linkedin.com/search/results/people/?currentCompany=%5B%2235639643%22%2C%228979%22%2C%22531312%22%2C%226132%22%2C%2225880%22%2C%2210718%22%2C%2277009034%22%2C%22970369%22%2C%22868912%22%2C%22579461%22%2C%2210039597%22%2C%2210559285%22%2C%2210876016%22%2C%22204630%22%2C%2279365269%22%2C%2279816292%22%2C%2280856181%22%5D&geoUrn=%5B%22101705918%22%2C%22104994045%22%2C%22106686604%22%2C%22106049128%22%2C%22107734735%22%5D&keywords=lead%20data%20scientist&origin=FACETED_SEARCH&page=5&searchId=25003ca8-2d98-45ab-b23f-280d8c230c99&sid=lGA\n"
     ]
    }
   ],
   "source": [
    "# Количество страниц результатов поиска для парсинга\n",
    "NUM_PAGES_TO_PARSE = int(input('Введите количество страниц для парсинга: '))\n",
    "\n",
    "# Название файла cookies\n",
    "COOKIES_PATH = '\\lincookies'\n",
    "\n",
    "# Папка для хранения файлов\n",
    "FILES_PATH = 'C:\\Recruiters'\n",
    "\n",
    "# Путь к файлу с URL\n",
    "URL_FILE_NAME = FILES_PATH + r\"\\urls.csv\"\n",
    "\n",
    "# Путь к файлу с инфо пользователей\n",
    "INFO_FILE_NAME = FILES_PATH + r\"\\user-info.csv\"\n",
    "\n",
    "# Путь к файлу с постами\n",
    "POSTS_FILE_NAME = FILES_PATH + r\"\\posts.csv\"\n",
    "\n",
    "# Суффикс ссылки на посты пользователя\n",
    "POSTS_URL_SUFFIX = 'recent-activity/all/'\n",
    "\n",
    "# Ввод поисковой строки\n",
    "SEARCH_URL = str(input('Введите строку поиска: '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb574cb8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Запуск драйвера для скрэпинга\n",
    "\n",
    "# Проверка наличия папки для файлов\n",
    "if not os.path.exists(FILES_PATH):\n",
    "    os.mkdir(FILES_PATH)\n",
    "\n",
    "caps = DesiredCapabilities().CHROME\n",
    "caps['pageLoadStrategy'] = 'normal'\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Скрытое ожидание загрузки всех элементов\n",
    "# Если будут проблемы, увеличить время ожидания\n",
    "driver.implicitly_wait(10)\n",
    "\n",
    "# Установлен широкоформатный размер экрана, чтобы нужные элементы помещались на экране\n",
    "driver.set_window_size(1920, 1080)\n",
    "\n",
    "# Вызов функции авторизации\n",
    "auth(driver)\n",
    "time.sleep(random.uniform(5, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc09192a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Парсинг страниц поисковой выдачи\n",
    "# Переход на стартовую страницу поиска\n",
    "driver.get(SEARCH_URL)\n",
    "\n",
    "# Вызов функции для парсинга\n",
    "search_pages(driver)\n",
    "\n",
    "# Пауза\n",
    "time.sleep(random.uniform(5, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eff1be63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Ручной сбор с одной страницы\n",
    "# url = 'https://www.linkedin.com/in/denis-dimitrov-66bbb3116'\n",
    "# get_and_save_profile_info(driver, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667ecbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выключаем драйвер скрэппинга\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fbcd5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
