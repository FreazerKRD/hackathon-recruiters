{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496b5a92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install pymystem3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe5c15fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from tqdm import notebook, tqdm\n",
    "import pymorphy2\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "import unicodedata\n",
    "import emoji\n",
    "from pymystem3 import Mystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0c1efe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\Recruiters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4fe651a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('full_df.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c2b2577",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\freazer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\freazer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# –£–¥–∞–ª–µ–Ω–∏–µ —Å—Å—ã–ª–æ–∫\n",
    "def remove_url_addresses(text):\n",
    "    # Define a regular expression for matching URL's\n",
    "    ip_regex = r'http\\S+|www.\\S+'\n",
    "    # Replace all occurrences of IP addresses with an empty string\n",
    "    return re.sub(ip_regex, '', text)\n",
    "\n",
    "def preprocess_text(df):\n",
    "    \"\"\"\n",
    "    The function preprocesses all textual columns in the DataFrame:\n",
    "    - removes stop words\n",
    "    - removes newline characters\n",
    "    - removes punctuation\n",
    "    - converts text to lower case\n",
    "    \"\"\"\n",
    "    # Initialize the set of stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    # Iterate over all columns in the DataFrame\n",
    "    for col in df.columns:\n",
    "        # Only consider string columns\n",
    "        if df[col].dtype == 'object' and col == 'text':\n",
    "            \n",
    "            # Apply preprocessing steps to each cell in the column\n",
    "            df[col] = df[col].apply(lambda x: \n",
    "                                    remove_url_addresses(\n",
    "                                    ' '.join([\n",
    "                                        word for word in word_tokenize(str(x).lower()) \n",
    "                                        if word not in stop_words and word not in string.punctuation and word != '\\n'\n",
    "                                            ])\n",
    "                                       )\n",
    "                                   )\n",
    "                # Use tqdm to track progress\n",
    "            df[col] = tqdm(df[col], desc=f\"Processing {col}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0326cb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('stopwords')\n",
    "\n",
    "# def preprocess_text_rus(text):\n",
    "#     # –£–¥–∞–ª–µ–Ω–∏–µ —ç–º–æ–¥–∑–∏\n",
    "#     text = emoji.demojize(text)\n",
    "    \n",
    "#     # –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ —Å–ª–æ–≤ –∫ –Ω–∞—á–∞–ª—å–Ω–æ–π —Ñ–æ—Ä–º–µ\n",
    "#     morph = MorphAnalyzer()\n",
    "    \n",
    "#     # –£–¥–∞–ª–µ–Ω–∏–µ –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤\n",
    "#     text = text.replace('\\n', '')\n",
    "    \n",
    "#     # –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–æ–ø-—Å–ª–æ–≤ –∏ —Å–ª–æ–≤/–ø–∞—Ä–∞–∑–∏—Ç–æ–≤\n",
    "#     stop_words = set(stopwords.words('russian')) | set(stopwords.words('english'))\n",
    "#     text = ' '.join([morph.parse(word)[0].normal_form for word in text.split() if word.lower() not in stop_words])\n",
    "    \n",
    "#     # –£–¥–∞–ª–µ–Ω–∏–µ –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏ –∏ –ø–µ—Ä–µ–Ω–æ—Å–æ–≤ —Å—Ç—Ä–æ–∫\n",
    "#     text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "#     return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "30ce177c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing text: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11238/11238 [00:00<00:00, 1248228.07it/s]\n"
     ]
    }
   ],
   "source": [
    "clean = preprocess_text(df.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c393916",
   "metadata": {},
   "outputs": [],
   "source": [
    "mystem = Mystem()\n",
    "clean['text'] = clean.loc[:5,'text'].apply(mystem.lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "450c0dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "russian_df = clean[clean['text'].apply(lambda x: re.match(r'[–ê-–Ø–∞-—è]+', x) is not None)]\n",
    "english_df = clean[clean['text'].apply(lambda x: re.match(r'[A-Za-z]+', x) is not None)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c424c30b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>status</th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "      <th>likes</th>\n",
       "      <th>reposts</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Middle Software Engineer - Yandex</td>\n",
       "      <td>https://www.linkedin.com/in/michilegorov</td>\n",
       "      <td>hi everyone looking new role would appreciate ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Talent Acquisition Manager | Recruitment Lead ...</td>\n",
       "      <td>https://www.linkedin.com/in/dariaivanova</td>\n",
       "      <td>apparently need use special resume template be...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Talent Acquisition Manager | Recruitment Lead ...</td>\n",
       "      <td>https://www.linkedin.com/in/dariaivanova</td>\n",
       "      <td>worldmentalhealthday want express importance k...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>Talent Acquisition Manager | Recruitment Lead ...</td>\n",
       "      <td>https://www.linkedin.com/in/dariaivanova</td>\n",
       "      <td>continue celebration customerserviceweek 'd li...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>Talent Acquisition Manager | Recruitment Lead ...</td>\n",
       "      <td>https://www.linkedin.com/in/dariaivanova</td>\n",
       "      <td>hiring product director appfollow appfollow ap...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11229</th>\n",
       "      <td>11229</td>\n",
       "      <td>Frontend Web Developer | JavaScript | TypeScri...</td>\n",
       "      <td>https://www.linkedin.com/in/dm-bychkov</td>\n",
       "      <td>javascript array methods cheatsheet üìçthis help...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11230</th>\n",
       "      <td>11230</td>\n",
       "      <td>Lead Data Analyst ‚Äì Playrix</td>\n",
       "      <td>https://www.linkedin.com/in/vladimirskabelkin</td>\n",
       "      <td>completed `` supply chain analytics python lin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11233</th>\n",
       "      <td>11233</td>\n",
       "      <td>Senior Data Scientist / NLP Engineer</td>\n",
       "      <td>https://www.linkedin.com/in/sshkarin</td>\n",
       "      <td>datacamp generalized linear models python</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11235</th>\n",
       "      <td>11235</td>\n",
       "      <td>Lead Data Analyst ‚Äì Playrix</td>\n",
       "      <td>https://www.linkedin.com/in/vladimirskabelkin</td>\n",
       "      <td>looking specialists work artificial intelligen...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11236</th>\n",
       "      <td>11236</td>\n",
       "      <td>Senior Data Scientist / NLP Engineer</td>\n",
       "      <td>https://www.linkedin.com/in/sshkarin</td>\n",
       "      <td>datacamp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6090 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                             status  \\\n",
       "3               3                  Middle Software Engineer - Yandex   \n",
       "7               7  Talent Acquisition Manager | Recruitment Lead ...   \n",
       "9               9  Talent Acquisition Manager | Recruitment Lead ...   \n",
       "10             10  Talent Acquisition Manager | Recruitment Lead ...   \n",
       "12             12  Talent Acquisition Manager | Recruitment Lead ...   \n",
       "...           ...                                                ...   \n",
       "11229       11229  Frontend Web Developer | JavaScript | TypeScri...   \n",
       "11230       11230                        Lead Data Analyst ‚Äì Playrix   \n",
       "11233       11233               Senior Data Scientist / NLP Engineer   \n",
       "11235       11235                        Lead Data Analyst ‚Äì Playrix   \n",
       "11236       11236               Senior Data Scientist / NLP Engineer   \n",
       "\n",
       "                                                 url  \\\n",
       "3           https://www.linkedin.com/in/michilegorov   \n",
       "7           https://www.linkedin.com/in/dariaivanova   \n",
       "9           https://www.linkedin.com/in/dariaivanova   \n",
       "10          https://www.linkedin.com/in/dariaivanova   \n",
       "12          https://www.linkedin.com/in/dariaivanova   \n",
       "...                                              ...   \n",
       "11229         https://www.linkedin.com/in/dm-bychkov   \n",
       "11230  https://www.linkedin.com/in/vladimirskabelkin   \n",
       "11233           https://www.linkedin.com/in/sshkarin   \n",
       "11235  https://www.linkedin.com/in/vladimirskabelkin   \n",
       "11236           https://www.linkedin.com/in/sshkarin   \n",
       "\n",
       "                                                    text likes  reposts  \\\n",
       "3      hi everyone looking new role would appreciate ...   2.0      0.0   \n",
       "7      apparently need use special resume template be...   5.0      0.0   \n",
       "9      worldmentalhealthday want express importance k...   2.0      0.0   \n",
       "10     continue celebration customerserviceweek 'd li...   0.0      0.0   \n",
       "12     hiring product director appfollow appfollow ap...  10.0      3.0   \n",
       "...                                                  ...   ...      ...   \n",
       "11229  javascript array methods cheatsheet üìçthis help...   7.0      7.0   \n",
       "11230  completed `` supply chain analytics python lin...   NaN      NaN   \n",
       "11233          datacamp generalized linear models python   NaN      NaN   \n",
       "11235  looking specialists work artificial intelligen...   6.0      5.0   \n",
       "11236                                           datacamp   NaN      NaN   \n",
       "\n",
       "       comments  \n",
       "3           0.0  \n",
       "7           0.0  \n",
       "9           0.0  \n",
       "10          0.0  \n",
       "12          0.0  \n",
       "...         ...  \n",
       "11229       4.0  \n",
       "11230       NaN  \n",
       "11233       NaN  \n",
       "11235       NaN  \n",
       "11236       NaN  \n",
       "\n",
       "[6090 rows x 7 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f3156f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean.to_csv('clean.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791e3c08",
   "metadata": {},
   "source": [
    "–î—É–±–ª–∏–∫–∞—Ç—ã —É–¥–∞–ª–µ–Ω—ã. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ce7f1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
